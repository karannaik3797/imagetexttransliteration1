{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransliterationLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb6LTLb2lUsA",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssxEyUg9_toA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qXX-I6E_5Nv",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwpztv2M_86c",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feKJLHF7_0u8",
        "colab_type": "code",
        "outputId": "23152cab-812f-4e71-b1f5-a5601ed2853f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7lyOEhsiFrV",
        "colab_type": "code",
        "outputId": "31ef67b5-3737-42f8-8ec4-15eafd258cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(eng_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA1r9A5I__Lv",
        "colab_type": "code",
        "outputId": "e66cc36c-8601-4bce-f099-b8e804f59b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PMlCoRyhOWn",
        "colab_type": "code",
        "outputId": "bb3198a1-308d-4b89-f18d-b0c63db5552f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(hindi_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaWRjlIzACQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhluUW3hAH_C",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO-C_N-BAE8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgJiMF2WAIsu",
        "colab_type": "code",
        "outputId": "c4361a29-bd37-42ff-954d-954a75460d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "train_data = TransliterationDataLoader('rI58TOlAScioEuPBbOYh_NEWS2012TrainingEnHi13937-1563719470862.xml')\n",
        "test_data = TransliterationDataLoader('njThAK0RQGeoOuE9rfwg_NEWS2012RefEnHi1000-1563719263404.xml')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie_4syjtAbHS",
        "colab_type": "text"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTLTQulvASyG",
        "colab_type": "code",
        "outputId": "f0bb0881-9d21-455d-f5a5-491ac91fbe75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "LALA - लाला\n",
            "DA - दा\n",
            "MANGAL - मंगल\n",
            "WALKER - वॉकर\n",
            "SCHOOL - स्कूल\n",
            "DASI - दासी\n",
            "ALMODA - अल्मोडा\n",
            "SUMMER - समर\n",
            "AMANDEEP - अमनदीप\n",
            "HIM - हिम\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFrACukV4H6",
        "colab_type": "code",
        "outputId": "6c3e0c81-a3d1-41d4-f4eb-1883a96e2663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "print('\\nSample data from test-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = test_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample data from test-set:\n",
            "RAHO - रहो\n",
            "EUGENIA - यूजेनिया\n",
            "CURTLY - कर्टली\n",
            "CURTLY - कर्टली\n",
            "MEXICAN - मैक्सिकन\n",
            "DEKH - देख\n",
            "JO - जॉ\n",
            "TUMHARA - तुम्हारा\n",
            "MASJID - मस्जिद\n",
            "MEI - में\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQqPyRVnAU0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeQ2H160Ad6W",
        "colab_type": "code",
        "outputId": "e093c220-0f98-4659-d42b-6b65d126990e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "hindi_rep = word_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_rep)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "डेली tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chtY9zfuAweA",
        "colab_type": "code",
        "outputId": "825eb9ba-5e4c-4430-b5c9-5c00a1c1f5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "eng_gt = gt_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_gt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DAILY tensor([[ 4],\n",
            "        [ 1],\n",
            "        [ 9],\n",
            "        [12],\n",
            "        [25],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxsu5kJxBjVD",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEp0Z4r4ByRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder_Attention_LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention_LSTM, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size # nH\n",
        "        self.output_size = output_size # nO # nI - Input Size \n",
        "        \n",
        "        self.encoder_rnn_cell = nn.LSTM(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.LSTM(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input) # (word_size,1,129) -> (word_size,1,256),(1,1,256)\n",
        "        if self.verbose:\n",
        "            print('Prior Encoder output', encoder_outputs.shape)\n",
        "            print('hidden.shape',hidden[0].shape)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size) # (word_size,1,256) -> (word_size,256)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden # (1,1,256)\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device) # (1,1,27)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs) # (word_size,256) -> (word_size,256)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state[0]', decoder_state[0].shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state[0].view(1, -1).repeat(encoder_outputs.shape[0], 1))# (1,1,256) -> (1,256) -> (word_size,256) -> (word_size,256)\n",
        "            V = self.attn(torch.tanh(U + W)) # (word_size,256) -> (word_size,1)\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) # (1,word_size) # softmax over the encoded inputs\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0), #(1,1,word_size) * (1,word_size,256) -> (1,1,256)\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "           #  embedding -  (1,1,27) -> (1,1,256)\n",
        "            embedding = self.out2hidden(decoder_input) # Converting the output of previous timestep to hidden_size\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0) # Concatenating input and context vector\n",
        "          # decoder_input - (1,512) -> (1,1,512)\n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state[0])  # (1,1,256) -> (1,1,27)\n",
        "            out = self.softmax(out) # (1,1,27)\n",
        "            outputs.append(out.view(1, -1)) # (1,1,27) -> (1,27)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcwDCxSCF8Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn_lstm = Transliteration_EncoderDecoder_Attention_LSTM(len(hindi_alpha2index), 256, len(eng_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecH25UkVB5r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(model,input_,max_output_chars,show_output=False):\n",
        "  model.eval().to(device_gpu)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(word_rep(input_,hindi_alpha2index,device_gpu),max_output_chars,device_gpu)\n",
        "    for i in range(len(outputs)):\n",
        "      output = torch.argmax(outputs[i],dim=1)\n",
        "      if show_output:\n",
        "        print(list(eng_alpha2index.keys())[output])\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80NU1d2IButY",
        "colab_type": "code",
        "outputId": "cecb9efb-5d7e-48e0-e8c3-1426e11b281e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "out = infer(net_attn_lstm, 'काला', 30,show_output=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prior Encoder output torch.Size([5, 1, 256])\n",
            "hidden.shape torch.Size([1, 1, 256])\n",
            "Encoder output torch.Size([5, 256])\n",
            "Decoder state[0] torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 27])\n",
            "U * Encoder output torch.Size([5, 256])\n",
            "W * Decoder state torch.Size([5, 256])\n",
            "V torch.Size([5, 1])\n",
            "Attn torch.Size([1, 5])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 27])\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n",
            "V\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-jJw2wgCpdV",
        "colab_type": "text"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4591OeaCNDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        gt = gt_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)  # Aggregating gradients across the decoder output timesteps\n",
        "            total_loss += loss                  # using retain_graph else graph will be destroyed\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLgEkRQzC7zS",
        "colab_type": "text"
      },
      "source": [
        "## Trainer Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUjBK3fiC3b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ4jlF-mBX38",
        "colab_type": "code",
        "outputId": "b86d24c4-3104-40bc-8d23-d099f02bef57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "%%time\n",
        "train_setup(net_attn_lstm, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.11384555697441101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wem3+Qlr/N5gAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "CPU times: user 1h 56min 29s, sys: 2min 32s, total: 1h 59min 1s\n",
            "Wall time: 1h 59min 33s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder_Attention_LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.36897388, 0.38029277, ..., 0.11386932, 0.11384556,\n",
              "       0.11382218])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmJ0f2hYrwTy",
        "colab_type": "code",
        "outputId": "df88164f-814d-4358-d712-810a70108c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train_setup(net_attn_lstm, lr=0.001, n_batches=200, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 199 Loss 0.06133890151977539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "CPU times: user 11min 37s, sys: 15.4 s, total: 11min 53s\n",
            "Wall time: 11min 56s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder_Attention_LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.05032725, 0.07133831, 0.06442379, 0.06158269,\n",
              "       0.06456303, 0.06240682, 0.06132104, 0.05926283, 0.05987208,\n",
              "       0.0586101 , 0.05749275, 0.05704434, 0.05721448, 0.05741291,\n",
              "       0.05705861, 0.05687021, 0.05687772, 0.0564871 , 0.05614211,\n",
              "       0.05525294, 0.05515954, 0.05505874, 0.05448919, 0.05405692,\n",
              "       0.05408506, 0.05384129, 0.0536423 , 0.0532073 , 0.05287726,\n",
              "       0.05278396, 0.05218295, 0.0517116 , 0.05150911, 0.05140712,\n",
              "       0.05097708, 0.05075206, 0.05030865, 0.05019988, 0.05019422,\n",
              "       0.04997632, 0.05012071, 0.0497988 , 0.04939653, 0.04909827,\n",
              "       0.04919659, 0.04897019, 0.04864532, 0.04850039, 0.04848431,\n",
              "       0.04845398, 0.0484133 , 0.04833595, 0.04823016, 0.04805741,\n",
              "       0.04828046, 0.04802947, 0.04787268, 0.04794984, 0.04819695,\n",
              "       0.04836131, 0.04838377, 0.04834223, 0.04834418, 0.04840546,\n",
              "       0.04828964, 0.048165  , 0.04881575, 0.0491281 , 0.04978885,\n",
              "       0.05009366, 0.05035383, 0.05062699, 0.05098419, 0.05122494,\n",
              "       0.05150493, 0.05191648, 0.05217882, 0.05221957, 0.0524267 ,\n",
              "       0.05288175, 0.05311838, 0.05346988, 0.05369765, 0.05406547,\n",
              "       0.05409774, 0.05430952, 0.05457187, 0.05476531, 0.05485732,\n",
              "       0.05509237, 0.0552805 , 0.05524576, 0.05542562, 0.05563093,\n",
              "       0.05582562, 0.05605617, 0.05617802, 0.05631332, 0.05640551,\n",
              "       0.05659847, 0.05675781, 0.05699006, 0.05712939, 0.05720615,\n",
              "       0.05727274, 0.05730304, 0.05742267, 0.05751142, 0.05766193,\n",
              "       0.0576321 , 0.05762503, 0.05779571, 0.05778536, 0.05789954,\n",
              "       0.05792049, 0.05809394, 0.05813529, 0.05814029, 0.0582471 ,\n",
              "       0.05843979, 0.05847576, 0.05860357, 0.0586901 , 0.05881019,\n",
              "       0.05896742, 0.05902538, 0.05911032, 0.0591926 , 0.05916709,\n",
              "       0.0592336 , 0.05914606, 0.05930959, 0.05937297, 0.05933134,\n",
              "       0.05941054, 0.05951611, 0.05965701, 0.0596178 , 0.05966849,\n",
              "       0.05964342, 0.05976471, 0.05973217, 0.05973817, 0.05979959,\n",
              "       0.0598447 , 0.05993641, 0.06000169, 0.05997798, 0.05997027,\n",
              "       0.06007564, 0.06008038, 0.06011709, 0.06023727, 0.06024572,\n",
              "       0.06039176, 0.06053345, 0.06056779, 0.0605528 , 0.06054448,\n",
              "       0.0606207 , 0.0606549 , 0.06074564, 0.0606765 , 0.06070376,\n",
              "       0.06068343, 0.06082503, 0.06085211, 0.0609028 , 0.06087087,\n",
              "       0.06096862, 0.06102691, 0.06103188, 0.06101941, 0.06110046,\n",
              "       0.06104024, 0.06118526, 0.0612515 , 0.06120014, 0.06120667,\n",
              "       0.06119074, 0.06122947, 0.06128724, 0.06132914, 0.061382  ,\n",
              "       0.06133624, 0.06135262, 0.06132379, 0.06133562, 0.06133801,\n",
              "       0.06144788, 0.06141673, 0.06140056, 0.0613564 , 0.06128877,\n",
              "       0.06119598, 0.06123847, 0.06120309, 0.06128341, 0.0613389 ,\n",
              "       0.06148093])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2Vu9qADQQG",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Xy0t2-DJaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30)\n",
        "    eng_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        eng_char = eng_alphabets[index+1]\n",
        "        eng_output += eng_char\n",
        "    print(word + ' - ' + eng_output)\n",
        "    return eng_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmLUc4KMDqLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(eng, eng_alpha2index, device)\n",
        "        outputs = infer(net, hindi, gt.shape[0])\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            eng_pos = indices.tolist()[0]\n",
        "            if eng_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B11YIjSsSdD",
        "colab_type": "text"
      },
      "source": [
        "#### Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRA1CCXz6OWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn_lstm = torch.load(\"./net_attn_hindi2eng_lstm_2.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAK7jRC442aM",
        "colab_type": "code",
        "outputId": "6538f04a-975e-4ae5-fd53-a9cf7bba065f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_attn = calc_accuracy(net_attn_lstm) * 100\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurracy with attention 76.2535798351976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik2-mnQAi_Cf",
        "colab_type": "code",
        "outputId": "7244ac6a-6b57-4070-fa8a-e951e0c18cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "infer(net_attn_lstm,\"उठता\",6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "U\n",
            "T\n",
            "H\n",
            "A\n",
            "T\n",
            "A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLPekjCm8Wx6",
        "colab_type": "code",
        "outputId": "2a55e278-bff7-4f28-ebb7-4419dc459e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "out = infer(net_attn_lstm,\"गोंबे\",6,show_output=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G\n",
            "O\n",
            "M\n",
            "B\n",
            "E\n",
            "-PAD-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_f_CIq0kv8I",
        "colab_type": "code",
        "outputId": "5bfc0e32-3721-4446-df07-5897ed15159e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "print('\\nSample data from test-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = test_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample data from test-set:\n",
            "SUBRAMANYAM - सुब्रमण्यम\n",
            "ASHOKA - अशोक\n",
            "KABIRA - कबीरा\n",
            "ISTVAN - इस्वॉन\n",
            "JET - जेट\n",
            "CROWN - क्राउन\n",
            "GOMBE - गोंबे\n",
            "RAJESH - राजेश\n",
            "LAYEGI - लाएगी\n",
            "INTERCONTINENTAL - इंटरकॉनटिनेंटल\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}